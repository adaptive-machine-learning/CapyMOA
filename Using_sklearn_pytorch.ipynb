{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b773bf8e-c420-44e1-80a6-99f75dd12268",
   "metadata": {},
   "source": [
    "## Using sklearn and pytorch\n",
    "\n",
    "* Demonstrate how someone can directly use sklearn learners or pytorch in CapyMOA.\n",
    "* Ideally, one should be free to use other learners\n",
    "\n",
    "**Accessing the input data x()**\n",
    "\n",
    "* Accessing the input data as a double array from an ```Instance``` through function ```x()```\n",
    "* Instances are represented internally as MOA Instances. \n",
    "\n",
    "**notebook last updated on 08/12/2023**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02aaf7b-11b5-4512-8a3b-5c26d8235b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:52:53.489371Z",
     "start_time": "2023-12-11T07:52:52.366276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOA jar path location (config.ini): ./jar/moa.jar\n",
      "JVM Location (system): \n",
      "\n",
      "JVM args: ['-Xmx8g', '-Xss10M']\n",
      "Sucessfully started the JVM and added MOA jar to the class path\n"
     ]
    }
   ],
   "source": [
    "from prepare_jpype import start_jpype\n",
    "\n",
    "start_jpype()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb3df1-190c-49ea-959b-292559df13e6",
   "metadata": {},
   "source": [
    "## 0. Reading data and accessing x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7be7ed-97d2-437a-9ed9-fb71e4f33328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:52:55.570196Z",
     "start_time": "2023-12-11T07:52:53.543410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.       0.056443 0.439155 0.003467 0.422915 0.414912], y: 1.0\n",
      "x: [0.021277 0.051699 0.415055 0.003467 0.422915 0.414912], y: 1.0\n",
      "x: [0.042553 0.051489 0.385004 0.003467 0.422915 0.414912], y: 1.0\n",
      "x: [0.06383  0.045485 0.314639 0.003467 0.422915 0.414912], y: 1.0\n",
      "x: [0.085106 0.042482 0.251116 0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.106383 0.041161 0.207528 0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.12766  0.041161 0.171824 0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.148936 0.041161 0.152782 0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.170213 0.041161 0.13493  0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.191489 0.041161 0.140583 0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.212766 0.044374 0.168997 0.003467 0.422915 0.414912], y: 1.0\n",
      "x: [0.234043 0.049868 0.212437 0.003467 0.422915 0.414912], y: 1.0\n",
      "x: [0.255319 0.051489 0.298721 0.003467 0.422915 0.414912], y: 1.0\n",
      "x: [0.276596 0.042482 0.39036  0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.297872 0.040861 0.402261 0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.319149 0.040711 0.462214 0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.340426 0.040861 0.488248 0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.361702 0.040711 0.493306 0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.382979 0.041041 0.53258  0.003467 0.422915 0.414912], y: 0.0\n",
      "x: [0.404255 0.041161 0.546415 0.003467 0.422915 0.414912], y: 0.0\n"
     ]
    }
   ],
   "source": [
    "from stream import stream_from_file\n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "\n",
    "## Opening a file as a stream\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "elec_stream.restart()\n",
    "i = 0\n",
    "while elec_stream.has_more_instances():\n",
    "    instance = elec_stream.next_instance()\n",
    "    if i < 20: # prevent printing all the instances\n",
    "        print(f'x: {instance.x()}, y: {instance.y()}')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d831be-3560-4efd-89bd-1ec71f001833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:52:55.581973Z",
     "start_time": "2023-12-11T07:52:55.571347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@attribute period numeric\n",
      "1.0\n",
      "@attribute nswprice numeric\n",
      "0.050679\n",
      "@attribute nswdemand numeric\n",
      "0.288753\n",
      "@attribute vicprice numeric\n",
      "0.003542\n",
      "@attribute vicdemand numeric\n",
      "0.355256\n",
      "@attribute transfer numeric\n",
      "0.23114\n"
     ]
    }
   ],
   "source": [
    "# Getting some extra information about the instance through the MOA representation. \n",
    "moa_instance = instance.get_MOA_InstanceExample().getData()\n",
    "\n",
    "for i in range(0, moa_instance.numInputAttributes()):\n",
    "    print(moa_instance.attribute(i))\n",
    "    print(moa_instance.value(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948e37ec-fbfd-43ea-a04a-7c11215452cc",
   "metadata": {},
   "source": [
    "## 1. Using scikit-learn\n",
    "\n",
    "* Example showing how a model from scikit-learn can be used with our ```Instance``` representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2745848d-43d1-4d9e-a191-14e6be61bf7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:53:25.006334Z",
     "start_time": "2023-12-11T07:52:55.581444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.8 s, sys: 701 ms, total: 29.5 s\n",
      "Wall time: 29.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "83.88064971751412"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "from evaluation import ClassificationEvaluator\n",
    "\n",
    "## Opening a file as a stream\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating a learner\n",
    "sklearn_SGD = linear_model.SGDClassifier()\n",
    "\n",
    "# Creating the evaluator\n",
    "ob_evaluator = ClassificationEvaluator(schema=elec_stream.get_schema())\n",
    "\n",
    "# elec_stream.schema.get_label_indexes() --> the class labels\n",
    "\n",
    "# Counter for partial fits\n",
    "partial_fit_count = 0\n",
    "while elec_stream.has_more_instances():\n",
    "    instance = elec_stream.next_instance()\n",
    "\n",
    "    prediction = -1\n",
    "    if partial_fit_count > 0: # scikit-learn does not allows invoking predict in a model that was not fit before\n",
    "        prediction = sklearn_SGD.predict([instance.x()])\n",
    "    ob_evaluator.update(instance.y(), prediction)\n",
    "    sklearn_SGD.partial_fit([instance.x()], [instance.y()], classes=elec_stream.schema.get_label_indexes())\n",
    "    partial_fit_count += 1\n",
    "\n",
    "ob_evaluator.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765c774-d5f0-468b-8bb0-8ff09dcea49a",
   "metadata": {},
   "source": [
    "### 1.1 Example using a MOA learner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9efdb8-fbe1-430d-b5c9-cc738d13e598",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:53:28.436508Z",
     "start_time": "2023-12-11T07:53:25.038218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "80.94103107344633"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from moa.classifiers.trees import HoeffdingAdaptiveTree\n",
    "from evaluation import ClassificationEvaluator\n",
    "from learners import MOAClassifier\n",
    "\n",
    "## Opening a file as a stream\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating a learner\n",
    "moa_HAT = MOAClassifier(schema=elec_stream.get_schema(), moa_learner=HoeffdingAdaptiveTree())\n",
    "\n",
    "# Creating the evaluator\n",
    "hat_evaluator = ClassificationEvaluator(schema=elec_stream.get_schema())\n",
    "\n",
    "while elec_stream.has_more_instances():\n",
    "    instance = elec_stream.next_instance()\n",
    "\n",
    "    prediction = moa_HAT.predict(instance)\n",
    "    hat_evaluator.update(instance.y(), prediction)\n",
    "    moa_HAT.train(instance)\n",
    "    partial_fit_count += 1\n",
    "\n",
    "hat_evaluator.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb71a0ef-44ff-4168-b5dd-62530f74d112",
   "metadata": {},
   "source": [
    "### 1.2 Using SKClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f457d2f-1b5d-4f41-a883-f11bc7a59814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:53:53.407047Z",
     "start_time": "2023-12-11T07:53:28.437780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 104 ms, total: 25.2 s\n",
      "Wall time: 25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "83.88064971751412"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "from learners import SKClassifier\n",
    "from evaluation import ClassificationEvaluator\n",
    "\n",
    "## Opening a file as a stream\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating a learner\n",
    "sklearn_SGD = SKClassifier(schema=elec_stream.get_schema(), sklearner=linear_model.SGDClassifier())\n",
    "\n",
    "# Creating the evaluator\n",
    "sklearn_SGD_evaluator = ClassificationEvaluator(schema=elec_stream.get_schema())\n",
    "\n",
    "while elec_stream.has_more_instances():\n",
    "    instance = elec_stream.next_instance()\n",
    "\n",
    "    prediction = sklearn_SGD.predict(instance)\n",
    "    sklearn_SGD_evaluator.update(instance.y(), prediction)\n",
    "    sklearn_SGD.train(instance)\n",
    "\n",
    "sklearn_SGD_evaluator.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff1ac9-07a1-4a0b-9bb5-f2afa79dd928",
   "metadata": {},
   "source": [
    "### 1.3 Using prequential evaluation + SKClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da2bba35-c258-4fc0-8932-f97d56e4e276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:54:18.675633Z",
     "start_time": "2023-12-11T07:53:53.407580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "83.88064971751412"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import prequential_evaluation\n",
    "\n",
    "## Opening a file as a stream\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating a learner\n",
    "sklearn_SGD = SKClassifier(schema=elec_stream.get_schema(), sklearner=linear_model.SGDClassifier())\n",
    "\n",
    "results_sklearn_SGD = prequential_evaluation(stream=elec_stream, learner=sklearn_SGD, window_size=4500)\n",
    "\n",
    "results_sklearn_SGD['cumulative'].accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9a931c-7b86-4bd6-8cda-179154e4b513",
   "metadata": {},
   "source": [
    "## 2. Using PyTorch\n",
    "* Example showing how a simple Pytorch model can be used with our ```Instance``` representation and MOA evaluator\n",
    "* Uses CPU device\n",
    "* Model is initialized after receiving the first instance"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set random seeds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b6d4a63467b23b5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import random\n",
    "random_seed=1\n",
    "random.seed(random_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T07:54:18.676689Z",
     "start_time": "2023-12-11T07:54:18.669019Z"
    }
   },
   "id": "2242896e95964ef4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define network structure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccbccfce41f2f18"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcd4d91-2b00-4d5a-9c54-f9dd6a291aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:54:22.106578Z",
     "start_time": "2023-12-11T07:54:18.675651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# Get cpu device for training.\n",
    "device = (\"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size=0, number_of_classes=0):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, number_of_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Using instance loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "882b6b292a2de100"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81092940-5a6b-4377-b550-ed6f5fee711a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:55:03.909308Z",
     "start_time": "2023-12-11T07:54:22.108679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Accuracy at 1000 : 55.2\n",
      "Accuracy at 2000 : 61.1\n",
      "Accuracy at 3000 : 61.266666666666666\n",
      "Accuracy at 4000 : 62.275000000000006\n",
      "Accuracy at 5000 : 63.0\n",
      "Accuracy at 6000 : 63.11666666666667\n",
      "Accuracy at 7000 : 63.01428571428571\n",
      "Accuracy at 8000 : 63.175000000000004\n",
      "Accuracy at 9000 : 63.866666666666674\n",
      "Accuracy at 10000 : 64.29\n",
      "Accuracy at 11000 : 64.53636363636363\n",
      "Accuracy at 12000 : 64.85833333333333\n",
      "Accuracy at 13000 : 65.26153846153846\n",
      "Accuracy at 14000 : 65.97142857142858\n",
      "Accuracy at 15000 : 66.43333333333334\n",
      "Accuracy at 16000 : 66.61875\n",
      "Accuracy at 17000 : 67.01176470588234\n",
      "Accuracy at 18000 : 67.52222222222221\n",
      "Accuracy at 19000 : 68.13157894736842\n",
      "Accuracy at 20000 : 68.58\n",
      "Accuracy at 21000 : 68.63809523809525\n",
      "Accuracy at 22000 : 69.06363636363636\n",
      "Accuracy at 23000 : 69.23913043478261\n",
      "Accuracy at 24000 : 69.5125\n",
      "Accuracy at 25000 : 69.71199999999999\n",
      "Accuracy at 26000 : 69.89230769230768\n",
      "Accuracy at 27000 : 70.1962962962963\n",
      "Accuracy at 28000 : 70.36428571428571\n",
      "Accuracy at 29000 : 70.4551724137931\n",
      "Accuracy at 30000 : 70.53333333333333\n",
      "Accuracy at 31000 : 70.6741935483871\n",
      "Accuracy at 32000 : 70.375\n",
      "Accuracy at 33000 : 70.4030303030303\n",
      "Accuracy at 34000 : 70.39117647058823\n",
      "Accuracy at 35000 : 70.3457142857143\n",
      "Accuracy at 36000 : 70.52222222222223\n",
      "Accuracy at 37000 : 70.57567567567567\n",
      "Accuracy at 38000 : 70.82631578947368\n",
      "Accuracy at 39000 : 71.06666666666666\n",
      "Accuracy at 40000 : 71.3\n",
      "Accuracy at 41000 : 71.42926829268292\n",
      "Accuracy at 42000 : 71.62619047619047\n",
      "Accuracy at 43000 : 71.8046511627907\n",
      "Accuracy at 44000 : 71.86590909090908\n",
      "Accuracy at 45000 : 71.95555555555555\n",
      "Accuracy at 45312 : 71.98313912429379\n"
     ]
    }
   ],
   "source": [
    "from evaluation import ClassificationEvaluator\n",
    "\n",
    "## Opening a file again to start from the beginning\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating the evaluator\n",
    "evaluator = ClassificationEvaluator(schema=elec_stream.get_schema())\n",
    "\n",
    "i = 0\n",
    "while elec_stream.has_more_instances():\n",
    "    i += 1\n",
    "    instance = elec_stream.next_instance()\n",
    "    if model is None:\n",
    "        moa_instance = instance.get_MOA_InstanceExample().getData()\n",
    "        # initialize the model and send it to the device\n",
    "        model = NeuralNetwork(input_size=elec_stream.get_schema().get_num_attributes(), \n",
    "                              number_of_classes=elec_stream.get_schema().get_num_classes()).to(device)\n",
    "        # set the optimizer\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "        print(model)\n",
    "    \n",
    "    X = torch.tensor(instance.x(), dtype=torch.float32)\n",
    "    y = torch.tensor(instance.y(), dtype=torch.long)\n",
    "    # set the device and add a dimension to the tensor\n",
    "    X, y = torch.unsqueeze(X.to(device), 0), torch.unsqueeze(y.to(device),0) \n",
    "    \n",
    "    # turn off gradient collection for test\n",
    "    with torch.no_grad():\n",
    "        pred = model(X)\n",
    "        prediction = torch.argmax(pred)\n",
    "\n",
    "    # update evaluator with predicted class\n",
    "    evaluator.update(instance.y(), prediction)\n",
    "  \n",
    "    # Compute prediction error\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f'Accuracy at {i} : {evaluator.accuracy()}')\n",
    "    \n",
    "print(f'Accuracy at {i} : {evaluator.accuracy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803eaab-eb2b-4c6e-a246-67f9ac71f70f",
   "metadata": {},
   "source": [
    "### 2.1 PyTorchClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c75513c-58e8-4499-bb19-2c58aea4567b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:55:03.918220Z",
     "start_time": "2023-12-11T07:55:03.907520Z"
    }
   },
   "outputs": [],
   "source": [
    "from learners import Classifier\n",
    "import numpy as np\n",
    "\n",
    "class PyTorchClassifier(Classifier):\n",
    "    def __init__(self, schema=None, random_seed=1, nn_model: nn.Module = None, optimizer=None, loss_fn=nn.CrossEntropyLoss(), device=(\"cpu\"), lr=1e-3):\n",
    "        super().__init__(schema, random_seed)\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.loss_fn = loss_fn\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "        \n",
    "        torch.manual_seed(random_seed)\n",
    "        \n",
    "        if nn_model is None:\n",
    "            self.set_model(None)\n",
    "        else:\n",
    "            self.model = nn_model.to(device)\n",
    "        if optimizer is None:\n",
    "            if self.model is not None:\n",
    "                self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.model)\n",
    "\n",
    "    def CLI_help(self):\n",
    "        return str('schema=None, random_seed=1, nn_model: nn.Module = None, optimizer=None, loss_fn=nn.CrossEntropyLoss(), device=(\"cpu\"), lr=1e-3')\n",
    "\n",
    "    def set_model(self, instance):\n",
    "        if self.schema is None:\n",
    "            moa_instance = instance.get_MOA_InstanceExample().getData()\n",
    "            self.model = NeuralNetwork(input_size=moa_instance.get_num_attributes(), number_of_classes=moa_instance.get_num_classes()).to(self.device)\n",
    "        elif instance is not None:\n",
    "            self.model = NeuralNetwork(input_size=self.schema.get_num_attributes(), number_of_classes=self.schema.get_num_classes()).to(self.device)\n",
    "            \n",
    "    def train(self, instance):\n",
    "        if self.model is None:\n",
    "            self.set_model(instance)\n",
    "    \n",
    "        X = torch.tensor(instance.x(), dtype=torch.float32)\n",
    "        y = torch.tensor(instance.y(), dtype=torch.long)\n",
    "        # set the device and add a dimension to the tensor\n",
    "        X, y = torch.unsqueeze(X.to(self.device), 0), torch.unsqueeze(y.to(self.device),0)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = self.model(X)\n",
    "        loss = self.loss_fn(pred, y)\n",
    "    \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def predict(self, instance):\n",
    "        return np.argmax(self.predict_proba(instance))\n",
    "\n",
    "    def predict_proba(self, instance):\n",
    "        if self.model is None:\n",
    "            self.set_model(instance)\n",
    "        X = torch.unsqueeze(torch.tensor(instance.x(), dtype=torch.float32).to(self.device), 0)\n",
    "        # turn off gradient collection\n",
    "        with torch.no_grad():\n",
    "            pred = np.asarray(self.model(X).numpy(), dtype=np.double)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.1 Example using PyTorchClassifier + the instance loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c01f8aea1b78936"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa7645f5-2c62-467a-b51c-5af1a0a48fb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:55:44.291257Z",
     "start_time": "2023-12-11T07:55:03.920370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "71.99417372881356"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import ClassificationEvaluator\n",
    "\n",
    "## Opening a file again to start from the beginning\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating the evaluator\n",
    "evaluator = ClassificationEvaluator(schema=elec_stream.get_schema())\n",
    "\n",
    "# Creating a learner\n",
    "simple_pyTorch_classifier = PyTorchClassifier(\n",
    "    schema=elec_stream.get_schema(), \n",
    "    nn_model=NeuralNetwork(input_size=elec_stream.get_schema().get_num_attributes(), number_of_classes=elec_stream.get_schema().get_num_classes()).to(device)\n",
    ")\n",
    "\n",
    "while elec_stream.has_more_instances():\n",
    "    instance = elec_stream.next_instance()\n",
    "\n",
    "    prediction = simple_pyTorch_classifier.predict(instance)\n",
    "    evaluator.update(instance.y(), prediction)\n",
    "    simple_pyTorch_classifier.train(instance)\n",
    "\n",
    "evaluator.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.2 Example using PyTorchClassifier and prequential_evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75ee1eb154c01996"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece5b5ff-be24-439c-bf53-7bf5d4fbf858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:56:27.716837Z",
     "start_time": "2023-12-11T07:55:44.287770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "71.98313912429379"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import prequential_evaluation\n",
    "\n",
    "## Opening a file as a stream\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating a learner\n",
    "simple_pyTorch_classifier = PyTorchClassifier(\n",
    "    schema=elec_stream.get_schema(), \n",
    "    nn_model=NeuralNetwork(input_size=elec_stream.get_schema().get_num_attributes(), number_of_classes=elec_stream.get_schema().get_num_classes()).to(device)\n",
    ")\n",
    "\n",
    "evaluator = prequential_evaluation(stream=elec_stream, learner=simple_pyTorch_classifier, window_size=4500)\n",
    "\n",
    "evaluator['cumulative'].accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f760b-7e5f-4f00-b8e9-cc8b7a5a8e72",
   "metadata": {},
   "source": [
    "### 2.2 How to use TensorBoard with PyTorch\n",
    "\n",
    "Install TensorBoard through the command line to visualize data you logged\n",
    "\n",
    "```sh\n",
    "pip install tensorboard\n",
    "```\n",
    "Clear any logs from previous runs\n",
    "\n",
    "```sh\n",
    "rm -rf ./runs\n",
    "```\n",
    "\n",
    "**TODO: create another notebook (for visualizations) and move this section**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create a SummaryWriter instance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaf035bef41c2ed2"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d2d7214-84a6-410e-977c-3b16a198347b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:56:27.869323Z",
     "start_time": "2023-12-11T07:56:27.717106Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Example using PyTorchClassifier + the instance loop + TensorBoard"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5f87ce2a3293c34"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from evaluation import ClassificationEvaluator\n",
    "\n",
    "## Opening a file again to start from the beginning\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating the evaluator\n",
    "evaluator = ClassificationEvaluator(schema=elec_stream.get_schema())\n",
    "\n",
    "# Creating a learner\n",
    "simple_pyTorch_classifier = PyTorchClassifier(\n",
    "    schema=elec_stream.get_schema(), \n",
    "    nn_model=NeuralNetwork(input_size=elec_stream.get_schema().get_num_attributes(), number_of_classes=elec_stream.get_schema().get_num_classes()).to(device)\n",
    ")\n",
    "\n",
    "i = 0\n",
    "while elec_stream.has_more_instances():\n",
    "    i += 1\n",
    "    instance = elec_stream.next_instance()\n",
    "\n",
    "    prediction = simple_pyTorch_classifier.predict(instance)\n",
    "    evaluator.update(instance.y(), prediction)\n",
    "    simple_pyTorch_classifier.train(instance)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        writer.add_scalar(\"accuracy\", evaluator.accuracy(), i)\n",
    "\n",
    "writer.add_scalar(\"accuracy\", evaluator.accuracy(), i)\n",
    "writer.flush()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T07:57:07.388352Z",
     "start_time": "2023-12-11T07:56:27.871621Z"
    }
   },
   "id": "b7f048d71276da1f"
  },
  {
   "cell_type": "markdown",
   "id": "7d38ffa8-4fff-470f-bbe3-e6ebe3e583b0",
   "metadata": {},
   "source": [
    "Call flush() method to make sure that all pending events have been written to disk.\n",
    "\n",
    "See torch.utils.tensorboard tutorials to find more TensorBoard visualization types you can log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "929d7e1a-5b7c-400e-a647-c565cb357d78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:57:07.435082Z",
     "start_time": "2023-12-11T07:57:07.388802Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you do not need the summary writer anymore, call close() method.\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8dc33-bbc9-4e63-b1ac-1a6d490f09ee",
   "metadata": {},
   "source": [
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "#### Run TensorBoard\n",
    "Now, start TensorBoard, specifying the root log directory you used above. \n",
    "Argument ``logdir`` points to directory where TensorBoard will look to find \n",
    "event files that it can display. TensorBoard will recursively walk \n",
    "the directory structure rooted at ``logdir``, looking for ``.*tfevents.*`` files.\n",
    "\n",
    "```sh\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "Go to the URL it provides\n",
    "\n",
    "This dashboard shows how the accuracy change with time. \n",
    "You can use it to also track training speed, learning rate, and other \n",
    "scalar values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e9306-f459-4d8a-8608-9bd71a7600ae",
   "metadata": {},
   "source": [
    "## 4. Preprocessing using MOA\n",
    "\n",
    "* Includes an example of how preprocessing (from MOA) can be used, **maybe this example could be moved elsewhere**\n",
    "* ```x()``` is read-only as of now, so one cannot preprocess instances\n",
    "* **TODO**: Allow modifying ```x()``` so that python-based preprocessing can be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d070de-8697-4f98-a11b-eab4e3d5c281",
   "metadata": {},
   "source": [
    "### 4.1 Running onlineBagging without any preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14681f54-23a1-4f93-9145-abf484c91c54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:57:09.985228Z",
     "start_time": "2023-12-11T07:57:07.392989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "79.05190677966102"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test-then-train loop\n",
    "from ensembles import OnlineBagging\n",
    "from evaluation import ClassificationEvaluator\n",
    "\n",
    "## Opening a file as a stream\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating a learner\n",
    "ob_learner = OnlineBagging(schema=elec_stream.get_schema(), ensemble_size=5)\n",
    "\n",
    "# Creating the evaluator\n",
    "ob_evaluator = ClassificationEvaluator(schema=elec_stream.get_schema())\n",
    "\n",
    "while elec_stream.has_more_instances():\n",
    "    instance = elec_stream.next_instance()\n",
    "    \n",
    "    prediction = ob_learner.predict(instance)\n",
    "    ob_evaluator.update(instance.y(), prediction)\n",
    "    ob_learner.train(instance)\n",
    "\n",
    "ob_evaluator.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1360ef-0583-4c87-8645-1e2d701fffca",
   "metadata": {},
   "source": [
    "### 4.2 Online Bagging using the preprocessing method from MOA\n",
    "* The API is still a bit rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6fb628f-aefc-4bf1-8322-a175a16170e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:57:09.990651Z",
     "start_time": "2023-12-11T07:57:09.985411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'RandomTreeGenerator '"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the creation string, the __class__ is needed as a parameter to the function is the class used. \n",
    "elec_stream.moa_stream.getCLICreationString(elec_stream.moa_stream.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cdc2a2f-3259-4431-943f-7392fe520e44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:57:10.037729Z",
     "start_time": "2023-12-11T07:57:09.991929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the number of attributes (including the output)\n",
    "elec_stream.get_schema().num_attributes_including_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae9bb646-e0d1-4de6-b5a1-cff0f0a1b172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T07:57:11.782832Z",
     "start_time": "2023-12-11T07:57:10.031608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "79.69412076271186"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stream import Stream\n",
    "from moa.streams.filters import StandardisationFilter, NormalisationFilter\n",
    "from moa.streams import FilteredStream\n",
    "\n",
    "# Open the stream from an ARFF file\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.arff\")\n",
    "# Create a FilterStream and use the NormalisationFilter\n",
    "elec_stream_normalised = Stream(CLI=f\"-s ({elec_stream.moa_stream.getCLICreationString(elec_stream.moa_stream.__class__)}) \\\n",
    "-f NormalisationFilter \", moa_stream=FilteredStream())\n",
    "\n",
    "# Creating a learner\n",
    "ob_learner = OnlineBagging(schema=elec_stream.get_schema(), ensemble_size=5)\n",
    "\n",
    "# Creating the evaluator\n",
    "ob_evaluator = ClassificationEvaluator(schema=elec_stream_normalised.get_schema())\n",
    "\n",
    "while elec_stream_normalised.has_more_instances():\n",
    "    instance = elec_stream_normalised.next_instance()\n",
    "    \n",
    "    prediction = ob_learner.predict(instance)\n",
    "    ob_evaluator.update(instance.y(), prediction)\n",
    "    ob_learner.train(instance)\n",
    "    # print(instance.x())\n",
    "\n",
    "ob_evaluator.accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
