{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a48e9306-f459-4d8a-8608-9bd71a7600ae",
   "metadata": {},
   "source": [
    "## Preprocessing using MOA\n",
    "\n",
    "* Includes an example of how preprocessing (from MOA) can be used.\n",
    "* ```x()``` is read-only as of now, so one cannot preprocess instances\n",
    "* **TODO**: Allow modifying ```x()``` so that python-based preprocessing can be used. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55d070de-8697-4f98-a11b-eab4e3d5c281",
   "metadata": {},
   "source": [
    "## 1. Running OnlineBagging without any preprocessing\n",
    "* This is just to give us a baseline to compare with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14681f54-23a1-4f93-9145-abf484c91c54",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-29T11:57:00.920700Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capymoa_root: /Users/ng98/Desktop/CODE/CapyMOA_Latest/src/capymoa\n",
      "MOA jar path location (config.ini): /Users/ng98/Desktop/CODE/CapyMOA_Latest/src/capymoa/jar/moa.jar\n",
      "JVM Location (system): \n",
      "JAVA_HOME: /Users/ng98/Library/Java/JavaVirtualMachines/openjdk-14.0.1/Contents/Home\n",
      "JVM args: ['-Xmx8g', '-Xss10M']\n",
      "Sucessfully started the JVM and added MOA jar to the class path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.05190677966102"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from capymoa.stream import stream_from_file\n",
    "from capymoa.classifier import OnlineBagging\n",
    "from capymoa.evaluation import ClassificationEvaluator\n",
    "\n",
    "DATA_PATH = \"../data/\"\n",
    "\n",
    "## Opening a file as a stream\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating a learner\n",
    "ob_learner = OnlineBagging(schema=elec_stream.get_schema(), ensemble_size=5)\n",
    "\n",
    "# Creating the evaluator\n",
    "ob_evaluator = ClassificationEvaluator(schema=elec_stream.get_schema())\n",
    "\n",
    "## Test-then-train loop\n",
    "while elec_stream.has_more_instances():\n",
    "    instance = elec_stream.next_instance()\n",
    "    \n",
    "    prediction = ob_learner.predict(instance)\n",
    "    ob_evaluator.update(instance.y_index, prediction)\n",
    "    ob_learner.train(instance)\n",
    "\n",
    "ob_evaluator.accuracy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c1360ef-0583-4c87-8645-1e2d701fffca",
   "metadata": {},
   "source": [
    "### OnlineBagging using the preprocessing method from MOA\n",
    "* Here we use ```NormalisationFilter``` filter from MOA to online normalise instances.\n",
    "* The API is still a bit rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9bb646-e0d1-4de6-b5a1-cff0f0a1b172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T11:52:48.998749Z",
     "start_time": "2024-04-29T11:52:45.889095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.69412076271186"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from capymoa.stream import Stream\n",
    "from moa.streams.filters import StandardisationFilter, NormalisationFilter\n",
    "from moa.streams import FilteredStream\n",
    "\n",
    "# Open the stream from an ARFF file\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.arff\")\n",
    "# Create a FilterStream and use the NormalisationFilter\n",
    "elec_stream_normalised = Stream(CLI=f\"-s ({elec_stream.moa_stream.getCLICreationString(elec_stream.moa_stream.__class__)}) \\\n",
    "-f NormalisationFilter \", moa_stream=FilteredStream())\n",
    "\n",
    "# Creating a learner\n",
    "ob_learner = OnlineBagging(schema=elec_stream.get_schema(), ensemble_size=5)\n",
    "\n",
    "# Creating the evaluator\n",
    "ob_evaluator = ClassificationEvaluator(schema=elec_stream_normalised.get_schema())\n",
    "\n",
    "while elec_stream_normalised.has_more_instances():\n",
    "    instance = elec_stream_normalised.next_instance()\n",
    "    \n",
    "    prediction = ob_learner.predict(instance)\n",
    "    ob_evaluator.update(instance.y_index, prediction)\n",
    "    ob_learner.train(instance)\n",
    "    # print(instance.x)\n",
    "\n",
    "ob_evaluator.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca35fc1b11b6047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
