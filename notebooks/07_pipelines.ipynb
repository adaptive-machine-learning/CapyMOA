{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b773bf8e-c420-44e1-80a6-99f75dd12268",
   "metadata": {},
   "source": [
    "## Pipelines and Transformers\n",
    "\n",
    "This notebook showcases the current version of data processing pipelines in CapyMOA. \n",
    "\n",
    "* Includes an example of how preprocessing can be accomplished via pipelines and transformers.\n",
    "* Transformers transform_instance an instance, e.g., using standardization, normalization, etc.\n",
    "* Pipelines bundle transformers and can also act as classifiers or regressors\n",
    "\n",
    "*Please note that this feature is still under development; some functionality might not yet be available or change in future releases.*\n",
    "\n",
    "**notebook last updated on 28/05/2024**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55d070de-8697-4f98-a11b-eab4e3d5c281",
   "metadata": {},
   "source": [
    "### 1. Running onlineBagging without any preprocessing\n",
    "\n",
    "First, let us have a look at a simple test-then-train classification example without pipelines. \n",
    "- We loop over the instances of the data stream\n",
    "- make a prediction,\n",
    "- update the evaluator with the prediction and label\n",
    "- and then train the classifier on the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14681f54-23a1-4f93-9145-abf484c91c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.05190677966102"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test-then-train loop\n",
    "from capymoa.stream import stream_from_file\n",
    "from capymoa.classifier import OnlineBagging\n",
    "from capymoa.evaluation import ClassificationEvaluator\n",
    "\n",
    "## Opening a file as a stream\n",
    "DATA_PATH = \"../data/\"\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.csv\")\n",
    "\n",
    "# Creating a learner\n",
    "ob_learner = OnlineBagging(schema=elec_stream.get_schema(), ensemble_size=5)\n",
    "\n",
    "# Creating the evaluator\n",
    "ob_evaluator = ClassificationEvaluator(schema=elec_stream.get_schema())\n",
    "\n",
    "while elec_stream.has_more_instances():\n",
    "    instance = elec_stream.next_instance()\n",
    "    \n",
    "    prediction = ob_learner.predict(instance)\n",
    "    ob_evaluator.update(instance.y_index, prediction)\n",
    "    ob_learner.train(instance)\n",
    "\n",
    "ob_evaluator.accuracy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c1360ef-0583-4c87-8645-1e2d701fffca",
   "metadata": {},
   "source": [
    "### 2. Online Bagging using pipelines and transformers\n",
    "\n",
    "If we want to perform some preprocessing, such as normalization or feature transformation, or a combination of both, we can chain multiple such `Transformer`s within a pipeline. The last step of a pipeline is a learner, such as capymoa classifier or regressor.\n",
    "\n",
    "Similar as classifiers and regressors, pipelines support `train` and `test`. Hence, we can use them in the same way as we would use other capymoa learners. Internally, the pipeline object passes an incoming instance from one transformer to the next. It then returns the prediction of the classifier / regressor using the transformed instance.\n",
    "\n",
    "Creating a pipeline consists of the following steps:\n",
    "1. Create a stream instance\n",
    "2. Initialize the transformers\n",
    "3. Initialize the learner\n",
    "4. Create the pipeline. Here, we use a `ClassifierPipeline`\n",
    "5. Use the pipeline the same way as any other learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9bb646-e0d1-4de6-b5a1-cff0f0a1b172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.59313206214689"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from capymoa.stream.preprocessing import MOATransformer\n",
    "from capymoa.stream.preprocessing import ClassifierPipeline\n",
    "from capymoa.stream import Stream\n",
    "from moa.streams.filters import AddNoiseFilter, NormalisationFilter\n",
    "from moa.streams import FilteredStream\n",
    "\n",
    "# Open the stream from an ARFF file\n",
    "elec_stream = stream_from_file(path_to_csv_or_arff=DATA_PATH+\"electricity.arff\")\n",
    "\n",
    "# Creating the transformer\n",
    "normalisation_transformer = MOATransformer(schema=elec_stream.get_schema(), moa_filter=NormalisationFilter())\n",
    "add_noise_transformer = MOATransformer(schema=normalisation_transformer.get_schema(), moa_filter=AddNoiseFilter())\n",
    "\n",
    "# Creating a learner\n",
    "ob_learner = OnlineBagging(schema=add_noise_transformer.get_schema(), ensemble_size=5)\n",
    "\n",
    "# Creating and populating the pipeline\n",
    "pipeline = ClassifierPipeline(transformers=[add_noise_transformer, normalisation_transformer],\n",
    "                              learner=ob_learner)\n",
    "\n",
    "# Alternative:\n",
    "# pipeline = ClassifierPipeline()\n",
    "# pipeline.add_transformer(add_noise_transformer)\n",
    "# pipeline.add_transformer(normalization_transformer)\n",
    "# pipeline.set_learner(ob_learner)\n",
    "\n",
    "# Creating the evaluator\n",
    "ob_evaluator = ClassificationEvaluator(schema=elec_stream.get_schema()) \n",
    "\n",
    "while elec_stream.has_more_instances():\n",
    "    instance = elec_stream.next_instance()\n",
    "    prediction = pipeline.predict(instance)\n",
    "    ob_evaluator.update(instance.y_index, prediction)\n",
    "    pipeline.train(instance)\n",
    "\n",
    "ob_evaluator.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f747c04-59ab-41cb-87ca-3d66ae75731a",
   "metadata": {},
   "source": [
    "Last, we can also get a textual representation of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11f5b39-bf53-496e-b42c-25f89458ff03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformer(AddNoiseFilter) | Transformer(NormalisationFilter) | OnlineBagging'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8271b-bbb7-4ca9-97f5-fb41e27ec4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
